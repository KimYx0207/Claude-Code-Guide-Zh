# -*- coding: utf-8 -*-
"""
é€‰é¢˜è¿‡æ»¤å™¨ V3.0 - åŒè½¨åˆ¶ç®€åŒ–ç‰ˆ
åŸºäº82ç¯‡å†å²æ–‡ç« æ•°æ®é©±åŠ¨è®¾è®¡

V3.0 æ ¸å¿ƒé€»è¾‘ï¼š
1. æ ¸å¿ƒå·¥å…·ç±»ï¼šå¤§å‚ + AIå‚ç›´å‚å•†çš„å·¥å…· â†’ ç¨³å®šæµé‡ï¼Œå¸¸å†™
2. æ³›AIè¯é¢˜ç±»ï¼šAIç°è±¡/è¶‹åŠ¿/çƒ­ç‚¹ â†’ ç ´åœˆæ½œåŠ›ï¼Œç²¾é€‰å†™

æ•°æ®éªŒè¯ç»“è®ºï¼š
- æ ¸å¿ƒå·¥å…·ç±»ï¼š54ç¯‡ï¼Œå¹³å‡é˜…è¯» 1798
- æ³›AIè¯é¢˜ç±»ï¼š25ç¯‡ï¼Œå¹³å‡é˜…è¯» 908
- æ ¸å¿ƒå·¥å…·ç±»å¹³å‡é˜…è¯»æ˜¯æ³›AIè¯é¢˜ç±»çš„2å€

è®¾è®¡ç†å¿µï¼š
- ä¸è¯„åˆ†ï¼Œåªåˆ†ç±»
- æ ¸å¿ƒå·¥å…·æ± ç”¨æ•°æ®éªŒè¯
- æ—¶æ•ˆæ€§å†³å®šå†™ä½œç­–ç•¥ï¼ˆå¿«å†™ vs æ…¢å†™ï¼‰
"""

import re
from pathlib import Path
from typing import Dict, List, Optional
from dataclasses import dataclass, field
from datetime import datetime


@dataclass
class FilterResultV3:
    """V3è¿‡æ»¤ç»“æœ"""
    category: str  # "æ ¸å¿ƒå·¥å…·ç±»" / "æ³›AIè¯é¢˜ç±»" / "ä¸å»ºè®®"
    worth_writing: bool
    tool_matched: Optional[str]  # åŒ¹é…åˆ°çš„å·¥å…·/å“ç‰Œ
    timeliness: str  # "çƒ­ç‚¹æœŸ" / "å¸¸é’æœŸ"
    strategy: str  # å†™ä½œç­–ç•¥å»ºè®®
    insights: List[str]
    historical_avg_reads: Optional[int]  # è¯¥å·¥å…·/å“ç‰Œçš„å†å²å¹³å‡é˜…è¯»


class TopicFilterV3:
    """é€‰é¢˜è¿‡æ»¤å™¨ V7.1 - åŒè½¨åˆ¶"""

    # æ ¸å¿ƒå·¥å…·æ± ï¼ˆæ•°æ®éªŒè¯é€šè¿‡ï¼ŒæŒ‰å¹³å‡é˜…è¯»æ’åºï¼‰
    # æ¥æºï¼š82ç¯‡æ–‡ç« æ•°æ®åˆ†æ
    CORE_TOOLS = {
        # === å¤§å‚å‡ºå“ ===
        "Google/Gemini": {
            "keywords": ["gemini", "google", "è°·æ­Œ", "g3", "bard"],
            "avg_reads": 3146,
            "tier": "å¤§å‚",
        },
        "ByteDance/å³æ¢¦": {
            "keywords": ["å³æ¢¦", "è±†åŒ…", "å­—èŠ‚", "jimeng", "doubao"],
            "avg_reads": 2927,
            "tier": "å¤§å‚",
        },
        "Anthropic/Claude": {
            "keywords": ["claude", "anthropic"],
            "avg_reads": 2118,
            "tier": "å¤§å‚",
        },
        "OpenAI/ChatGPT": {
            "keywords": ["chatgpt", "gpt", "openai", "gpt-4", "gpt-5", "gpt5", "gpt4"],
            "avg_reads": 675,  # ä½äºé¢„æœŸï¼Œä½†ä»æ˜¯å¤§å‚
            "tier": "å¤§å‚",
        },
        "DeepSeek": {
            "keywords": ["deepseek", "æ·±åº¦æ±‚ç´¢"],
            "avg_reads": 1048,
            "tier": "å¤§å‚",
        },
        "Kimi/æœˆä¹‹æš—é¢": {
            "keywords": ["kimi", "æœˆä¹‹æš—é¢", "moonshot"],
            "avg_reads": 3448,
            "tier": "å¤§å‚",
        },
        "ç™¾åº¦/æ–‡å¿ƒ": {
            "keywords": ["æ–‡å¿ƒ", "ç™¾åº¦", "ernie", "wenxin"],
            "avg_reads": None,  # æ— æ•°æ®
            "tier": "å¤§å‚",
        },
        "é˜¿é‡Œ/é€šä¹‰": {
            "keywords": ["é€šä¹‰", "é˜¿é‡Œ", "qwen", "tongyi"],
            "avg_reads": None,
            "tier": "å¤§å‚",
        },
        "Microsoft/Copilot": {
            "keywords": ["copilot", "microsoft", "å¾®è½¯", "bing"],
            "avg_reads": None,
            "tier": "å¤§å‚",
        },
        "Meta/Llama": {
            "keywords": ["llama", "meta ai", "facebook ai"],
            "avg_reads": None,
            "tier": "å¤§å‚",
        },

        # === AIå‚ç›´å‚å•† ===
        "Cursor": {
            "keywords": ["cursor"],
            "avg_reads": 1246,
            "tier": "AIå‚ç›´",
        },
        "Codex": {
            "keywords": ["codex"],
            "avg_reads": 1199,
            "tier": "AIå‚ç›´",
        },
        "Coze": {
            "keywords": ["coze", "æ‰£å­"],
            "avg_reads": 689,
            "tier": "AIå‚ç›´",
        },
        "Midjourney": {
            "keywords": ["midjourney", "mj", "niji"],
            "avg_reads": None,
            "tier": "AIå‚ç›´",
        },
        "Runway": {
            "keywords": ["runway"],
            "avg_reads": None,
            "tier": "AIå‚ç›´",
        },
        "Perplexity": {
            "keywords": ["perplexity"],
            "avg_reads": None,
            "tier": "AIå‚ç›´",
        },
        "Suno": {
            "keywords": ["suno"],
            "avg_reads": None,
            "tier": "AIå‚ç›´",
        },
        "å¯çµ": {
            "keywords": ["å¯çµ", "kling"],
            "avg_reads": None,
            "tier": "AIå‚ç›´",
        },
        "Windsurf": {
            "keywords": ["windsurf", "codeium"],
            "avg_reads": None,
            "tier": "AIå‚ç›´",
        },
        "Bolt": {
            "keywords": ["bolt.new", "bolt"],
            "avg_reads": None,
            "tier": "AIå‚ç›´",
        },
        "v0": {
            "keywords": ["v0.dev", "v0"],
            "avg_reads": None,
            "tier": "AIå‚ç›´",
        },
        "Replit": {
            "keywords": ["replit"],
            "avg_reads": None,
            "tier": "AIå‚ç›´",
        },

        # === Claude Code ç”Ÿæ€ ===
        "Claude Code": {
            "keywords": ["claude code", "cc", "claude-code"],
            "avg_reads": 2118,  # ç»§æ‰¿Claudeçš„æ•°æ®
            "tier": "CCç”Ÿæ€",
        },
        "MCP": {
            "keywords": ["mcp", "model context protocol"],
            "avg_reads": 1500,  # ä¼°ç®—
            "tier": "CCç”Ÿæ€",
        },
        "Skills": {
            "keywords": ["skills", "skill", "æŠ€èƒ½"],
            "avg_reads": 2000,  # ä¼°ç®—
            "tier": "CCç”Ÿæ€",
        },
        "Hooks": {
            "keywords": ["hooks", "hook"],
            "avg_reads": 1670,  # å®é™…æ•°æ®
            "tier": "CCç”Ÿæ€",
        },
    }

    # çƒ­ç‚¹æœŸä¿¡å·è¯
    HOTSPOT_SIGNALS = [
        # æ—¶é—´ç±»
        "å‘å¸ƒ", "ä¸Šçº¿", "æ›´æ–°", "æ¨å‡º", "åˆšåˆš", "ä»Šå¤©", "æ˜¨æ™š", "ä»Šæ—©",
        "æœ€æ–°", "æ–°ç‰ˆ", "æ–°åŠŸèƒ½", "å®˜å®£", "é‡ç£…", "çªå‘", "ç´§æ€¥",
        # äº‹ä»¶ç±»
        "è¢«å°", "é™åˆ¶", "æ¶¨ä»·", "é™ä»·", "å…è´¹", "å¼€æ”¾",
        # é‡å¤§æ–°é—»ç±»
        "ä¼°å€¼", "èèµ„", "æ”¶è´­", "ä¸Šå¸‚", "è­¦æŠ¥", "æ…Œäº†", "ç‚¸äº†", "ç–¯äº†",
        "å®£å¸ƒ", "ç¡®è®¤", "æ›å…‰", "æ³„éœ²", "é¦–å‘", "ç‹¬å®¶",
        # äº§å“åŠ¨æ€ç±»
        "æ”¾å¤§æ‹›", "å¤§æ›´æ–°", "å…¨æ–°", "é©å‘½", "é¢ è¦†", "ç™»é¡¶", "ç¬¬ä¸€",
    ]


    def __init__(self, articles_dir: str = "articles"):
        self.articles_dir = Path(articles_dir)

    def filter(self, topic: str, context: Optional[str] = None) -> FilterResultV3:
        """
        è¿‡æ»¤é€‰é¢˜

        Args:
            topic: é€‰é¢˜æè¿°
            context: é¢å¤–ä¸Šä¸‹æ–‡

        Returns:
            FilterResultV3: è¿‡æ»¤ç»“æœ
        """
        full_text = f"{topic} {context or ''}".lower()
        insights = []

        # Step 1: æ£€æŸ¥æ˜¯å¦åŒ¹é…æ ¸å¿ƒå·¥å…·æ± 
        matched_tool, tool_info = self._match_core_tool(full_text)

        if matched_tool:
            # æ ¸å¿ƒå·¥å…·ç±»
            timeliness = self._check_timeliness(full_text)
            strategy = self._get_strategy("æ ¸å¿ƒå·¥å…·ç±»", timeliness, tool_info)

            insights.append(f"âœ… åŒ¹é…æ ¸å¿ƒå·¥å…·ï¼š{matched_tool}ï¼ˆ{tool_info['tier']}ï¼‰")
            if tool_info.get("avg_reads"):
                insights.append(f"ğŸ“Š å†å²å¹³å‡é˜…è¯»ï¼š{tool_info['avg_reads']}")
            insights.append(f"â° æ—¶æ•ˆæ€§ï¼š{timeliness}")

            return FilterResultV3(
                category="æ ¸å¿ƒå·¥å…·ç±»",
                worth_writing=True,
                tool_matched=matched_tool,
                timeliness=timeliness,
                strategy=strategy,
                insights=insights,
                historical_avg_reads=tool_info.get("avg_reads"),
            )

        # Step 2: æ£€æŸ¥æ˜¯å¦æ˜¯æ³›AIè¯é¢˜
        is_ai_topic, ai_signals = self._check_ai_topic(full_text)

        if is_ai_topic:
            timeliness = self._check_timeliness(full_text)
            strategy = self._get_strategy("æ³›AIè¯é¢˜ç±»", timeliness, None)

            insights.append(f"ğŸŒ æ³›AIè¯é¢˜ï¼š{', '.join(ai_signals[:3])}")
            insights.append(f"â° æ—¶æ•ˆæ€§ï¼š{timeliness}")
            insights.append("âš ï¸ é£é™©æç¤ºï¼šæ³›AIè¯é¢˜å¹³å‡é˜…è¯»908ï¼Œä¸çˆ†å°±æƒ¨")
            insights.append("ğŸ’¡ å»ºè®®ï¼šé€‰æ‹©æœ‰ç ´åœˆæ½œåŠ›çš„è§’åº¦ï¼Œå‚è€ƒå¡å…¹å…‹çš„åšæ³•")

            return FilterResultV3(
                category="æ³›AIè¯é¢˜ç±»",
                worth_writing=True,
                tool_matched=None,
                timeliness=timeliness,
                strategy=strategy,
                insights=insights,
                historical_avg_reads=908,  # æ³›AIè¯é¢˜å¹³å‡å€¼
            )

        # Step 3: ä¸å»ºè®®å†™
        insights.append("âŒ æœªåŒ¹é…æ ¸å¿ƒå·¥å…·æ± ")
        insights.append("âŒ æœªè¯†åˆ«ä¸ºæ³›AIè¯é¢˜")
        insights.append("ğŸ’¡ å»ºè®®ï¼šè€ƒè™‘å…³è”ä¸€ä¸ªæ ¸å¿ƒå·¥å…·ï¼Œæˆ–æ‰¾ä¸€ä¸ªAIçƒ­ç‚¹è§’åº¦")

        return FilterResultV3(
            category="ä¸å»ºè®®",
            worth_writing=False,
            tool_matched=None,
            timeliness="æ— ",
            strategy="ä¸å»ºè®®å†™ï¼Œæˆ–éœ€è¦é‡æ–°å®šä½è§’åº¦",
            insights=insights,
            historical_avg_reads=None,
        )

    def _match_core_tool(self, text: str) -> tuple:
        """åŒ¹é…æ ¸å¿ƒå·¥å…·æ± """
        for tool_name, tool_info in self.CORE_TOOLS.items():
            for keyword in tool_info["keywords"]:
                # ä½¿ç”¨å•è¯è¾¹ç•ŒåŒ¹é…ï¼Œé¿å…è¯¯åŒ¹é…
                if keyword.lower() in text:
                    return tool_name, tool_info
        return None, None

    def _check_timeliness(self, text: str) -> str:
        """æ£€æŸ¥æ—¶æ•ˆæ€§"""
        # 1. æ£€æŸ¥çƒ­ç‚¹ä¿¡å·è¯
        for signal in self.HOTSPOT_SIGNALS:
            if signal in text:
                return "çƒ­ç‚¹æœŸ"

        # 2. æ£€æŸ¥ç‰ˆæœ¬å·ï¼ˆv5, 2.0, 3.1ç­‰ â†’ çƒ­ç‚¹æœŸï¼‰
        if re.search(r'[vV]?\d+(\.\d+)?', text):
            # æ’é™¤ä¸€äº›å¸¸è§çš„éç‰ˆæœ¬æ•°å­—ï¼ˆå¦‚"100+"ã€"60å€"ç­‰ï¼‰
            version_match = re.search(r'[vV]\d+(\.\d+)?|\b\d+\.\d+\b', text)
            if version_match:
                return "çƒ­ç‚¹æœŸ"

        return "å¸¸é’æœŸ"

    def _check_ai_topic(self, text: str) -> tuple:
        """æ£€æŸ¥æ˜¯å¦æ˜¯æ³›AIè¯é¢˜"""
        ai_signals = []

        # AIç›¸å…³é€šç”¨è¯
        ai_keywords = [
            "ai", "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "å¤§æ¨¡å‹", "llm",
            "ç”Ÿæˆå¼", "aigc", "æ™ºèƒ½ä½“", "agent",
            "æ›¿ä»£", "å¤±ä¸š", "æœªæ¥", "å˜é©", "é¢ è¦†",
            "æç¤ºè¯", "prompt", "å·¥ä½œæµ", "è‡ªåŠ¨åŒ–",
        ]

        for kw in ai_keywords:
            if kw in text:
                ai_signals.append(kw)

        # è‡³å°‘åŒ¹é…2ä¸ªAIç›¸å…³è¯æ‰ç®—æ³›AIè¯é¢˜
        return len(ai_signals) >= 1, ai_signals

    def _get_strategy(self, category: str, timeliness: str, tool_info: Optional[dict]) -> str:
        """è·å–å†™ä½œç­–ç•¥"""
        if category == "æ ¸å¿ƒå·¥å…·ç±»":
            if timeliness == "çƒ­ç‚¹æœŸ":
                return "ğŸ”¥ è¿½çƒ­ç‚¹ï¼Œå¿«å†™ï¼æŠ¢æ—¶æ•ˆï¼Œ24å°æ—¶å†…å‘å¸ƒ"
            else:
                return "ğŸ“š åšæ•™ç¨‹ï¼Œæ…¢å†™ã€‚æ·±åº¦å†…å®¹ï¼Œæ‰“ç£¨è´¨é‡"
        elif category == "æ³›AIè¯é¢˜ç±»":
            if timeliness == "çƒ­ç‚¹æœŸ":
                return "ğŸ¯ åšçˆ†æ¬¾ï¼å¿«é€Ÿäº§å‡ºï¼Œé…åˆçƒ­ç‚¹ä¼ æ’­"
            else:
                return "ğŸ¤” è°¨æ…å†™ã€‚éœ€è¦ç‹¬ç‰¹è§’åº¦æ‰èƒ½ç ´åœˆ"
        return "ä¸å»ºè®®"

    def generate_report(self, result: FilterResultV3, topic: str) -> str:
        """ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"""
        lines = [
            "=" * 60,
            "ğŸ¯ é€‰é¢˜è¿‡æ»¤å™¨ V7.1 - åŒè½¨åˆ¶",
            "=" * 60,
            "",
            f"ğŸ“ é€‰é¢˜ï¼š{topic}",
            "",
            "-" * 60,
            f"ğŸ“‚ åˆ†ç±»ï¼š{result.category}",
            f"âœ… åˆ¤æ–­ï¼š{'å€¼å¾—å†™' if result.worth_writing else 'ä¸å»ºè®®å†™'}",
        ]

        if result.tool_matched:
            lines.append(f"ğŸ”§ å·¥å…·ï¼š{result.tool_matched}")

        if result.historical_avg_reads:
            lines.append(f"ğŸ“Š å†å²å¹³å‡é˜…è¯»ï¼š{result.historical_avg_reads}")

        lines.extend([
            f"â° æ—¶æ•ˆæ€§ï¼š{result.timeliness}",
            "",
            "-" * 60,
            f"ğŸ“‹ ç­–ç•¥ï¼š{result.strategy}",
            "-" * 60,
            "",
            "ğŸ’¡ åˆ†æï¼š",
        ])

        for insight in result.insights:
            lines.append(f"  {insight}")

        lines.extend([
            "",
            "=" * 60,
            "ğŸ“Š V3æ•°æ®åŸºå‡†ï¼ˆ82ç¯‡éªŒè¯ï¼‰ï¼š",
            "=" * 60,
            "  æ ¸å¿ƒå·¥å…·ç±»ï¼š54ç¯‡ï¼Œå¹³å‡é˜…è¯» 1798",
            "  æ³›AIè¯é¢˜ç±»ï¼š25ç¯‡ï¼Œå¹³å‡é˜…è¯» 908",
            "",
            "  TOPå·¥å…·æ’åï¼š",
            "  1. Kimi: 3448    2. Gemini: 3146   3. å³æ¢¦: 2927",
            "  4. Claude: 2118  5. Cursor: 1246   6. Codex: 1199",
            "",
        ])

        return "\n".join(lines)


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import sys
    import io

    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

    if len(sys.argv) < 2:
        print("ç”¨æ³•: python topic_filter.py <é€‰é¢˜æè¿°> [é¢å¤–ä¸Šä¸‹æ–‡]")
        print("")
        print("ç¤ºä¾‹:")
        print("  python topic_filter.py 'Gemini 2.0å‘å¸ƒäº†'")
        print("  python topic_filter.py 'Claude Code Hooksä½¿ç”¨æ•™ç¨‹'")
        print("  python topic_filter.py 'AIä¼šå–ä»£ç¨‹åºå‘˜å—'")
        sys.exit(1)

    topic = sys.argv[1]
    context = sys.argv[2] if len(sys.argv) > 2 else None

    filter_tool = TopicFilterV3()
    result = filter_tool.filter(topic, context)
    print(filter_tool.generate_report(result, topic))


if __name__ == "__main__":
    main()
