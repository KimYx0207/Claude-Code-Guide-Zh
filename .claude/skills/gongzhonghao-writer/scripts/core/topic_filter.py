# -*- coding: utf-8 -*-
"""
é€‰é¢˜è¿‡æ»¤å™¨ V9.0 - ä¸‰å±‚æ¶æ„ç‰ˆ
ä¼˜å…ˆçº§å…¬å¼ï¼špriority = layer_score Ã— timeliness Ã— type_weight Ã— brand_tier Ã· risk
"""

import sys
import re
from pathlib import Path
from typing import Dict, List, Optional, Set
from dataclasses import dataclass, field
from datetime import datetime

# æ·»åŠ configç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from config.loader import load_config


@dataclass
class TopicType:
    """é€‰é¢˜ç±»å‹"""
    name: str
    weight: float
    keywords: List[str]


@dataclass
class FilterResultV8:
    """V8è¿‡æ»¤ç»“æœ - ä¸‰å±‚æ¶æ„ç‰ˆ"""
    # åŸºç¡€ä¿¡æ¯
    layer: str  # "layer1" / "layer2" / "layer3" / "rejected"
    worth_writing: bool
    priority_score: float  # ä¼˜å…ˆçº§åˆ†æ•°

    # å·¥å…·/å“ç‰Œä¿¡æ¯
    tool_matched: Optional[str]
    tool_tier: Optional[str]  # S/A/B
    avg_reads_estimate: int

    # åˆ†ç±»ä¿¡æ¯ï¼ˆå¯å¤šé€‰ï¼‰
    topic_types: List[str]  # ["çƒ­ç‚¹å‹", "æ•™ç¨‹å‹"] ç­‰
    timeliness: str  # "ç´§æ€¥çƒ­ç‚¹" / "è¿‘æœŸæ›´æ–°" / "å¸¸é’å†…å®¹"
    risk_level: str  # "low" / "medium" / "high"

    # ç­–ç•¥å»ºè®®
    strategy: str
    deadline_hint: str  # "24å°æ—¶å†…" / "72å°æ—¶å†…" / "å¯æ‰“ç£¨"

    # åˆ†ææ˜ç»†
    insights: List[str]
    score_breakdown: Dict[str, float]  # åˆ†æ•°æ‹†è§£


class TopicFilterV8:
    """é€‰é¢˜è¿‡æ»¤å™¨ V8.0 - ä¸‰å±‚æ¶æ„+å¤šç±»å‹+ä¼˜å…ˆçº§å…¬å¼"""

    def __init__(self):
        """åˆå§‹åŒ–ï¼šä»é…ç½®åŠ è½½"""
        # åŠ è½½é…ç½®
        self.tools_config = load_config('core_tools_pool')
        self.quality_config = load_config('quality_config')
        self.brands_config = load_config('brands_config')

        # è§£æé…ç½®
        self._load_layer1_tools()
        self._load_layer2_ecosystem()
        self._load_topic_types()
        self._load_timeliness_rules()
        self._load_priority_formula()

    def _load_layer1_tools(self):
        """åŠ è½½Layer1æ ¸å¿ƒå·¥å…·"""
        layer1 = self.tools_config.get('layer1_official', {}).get('tools', {})
        self.layer1_tools = {}
        for name, info in layer1.items():
            self.layer1_tools[name] = {
                'keywords': [k.lower() for k in info.get('keywords', [name.lower()])],
                'tier': info.get('tier', 'B'),
                'avg_reads': info.get('avg_reads', 1000)
            }

    def _load_layer2_ecosystem(self):
        """åŠ è½½Layer2ç”Ÿæ€å…³é”®è¯"""
        layer2 = self.tools_config.get('layer2_ecosystem', {})
        self.ecosystem_keywords = []
        rules = layer2.get('github_filter_rules', {})
        self.ecosystem_keywords = [k.lower() for k in rules.get('must_contain_any', [])]

        self.ecosystem_categories = layer2.get('categories', {})

    def _load_topic_types(self):
        """åŠ è½½é€‰é¢˜ç±»å‹"""
        types_config = self.tools_config.get('topic_types', {}).get('types', {})
        self.topic_types = {}
        for name, info in types_config.items():
            self.topic_types[name] = TopicType(
                name=name,
                weight=info.get('weight', 1.0),
                keywords=[k.lower() for k in info.get('keywords', [])]
            )

        # é»˜è®¤ç±»å‹ï¼ˆå¦‚æœé…ç½®ä¸ºç©ºï¼‰
        if not self.topic_types:
            self.topic_types = {
                "çƒ­ç‚¹å‹": TopicType("çƒ­ç‚¹å‹", 1.6, ["å‘å¸ƒ", "æ›´æ–°", "å®˜å®£", "é¦–å‘"]),
                "å·¥å…·å‹": TopicType("å·¥å…·å‹", 1.5, ["ç¥å™¨", "å·¥å…·", "æ’ä»¶", "æ‰©å±•", "mcp"]),
                "æ•™ç¨‹å‹": TopicType("æ•™ç¨‹å‹", 1.4, ["æ‰‹æŠŠæ‰‹", "æ•™ä½ ", "æ•™ç¨‹", "å…¥é—¨", "æŒ‡å—"]),
                "ç¾Šæ¯›å‹": TopicType("ç¾Šæ¯›å‹", 1.3, ["å…è´¹", "ç™½å«–", "è–…ç¾Šæ¯›", "çœé’±"]),
                "ç—›ç‚¹å‹": TopicType("ç—›ç‚¹å‹", 1.4, ["è§£å†³", "æŠ¥é”™", "é—®é¢˜", "ä¿®å¤", "é¿å‘"]),
                "æµ‹è¯„å‹": TopicType("æµ‹è¯„å‹", 1.2, ["æµ‹è¯„", "å¯¹æ¯”", "å®æµ‹", "ä½“éªŒ"]),
            }

    def _load_timeliness_rules(self):
        """åŠ è½½æ—¶æ•ˆæ€§è§„åˆ™"""
        rules = self.tools_config.get('timeliness_rules', {})
        hot_signals = rules.get('hot_signals', {})

        self.immediate_keywords = hot_signals.get('immediate', {}).get('keywords', [
            "åˆšåˆš", "ä»Šå¤©", "å‘å¸ƒ", "ä¸Šçº¿", "å®˜å®£", "breaking"
        ])
        self.immediate_boost = hot_signals.get('immediate', {}).get('priority_boost', 2.0)

        self.recent_keywords = hot_signals.get('recent', {}).get('keywords', [
            "æœ€æ–°", "æ›´æ–°", "æ–°ç‰ˆ", "å‡çº§"
        ])
        self.recent_boost = hot_signals.get('recent', {}).get('priority_boost', 1.5)

        self.evergreen_keywords = rules.get('evergreen', {}).get('keywords', [
            "æ•™ç¨‹", "å…¥é—¨", "æŒ‡å—", "è¯¦è§£", "åŸç†"
        ])

    def _load_priority_formula(self):
        """åŠ è½½ä¼˜å…ˆçº§å…¬å¼å‚æ•°"""
        formula = self.tools_config.get('priority_formula', {})

        self.layer_scores = formula.get('layer_scores', {
            "layer1": 100,
            "layer2": 75,
            "layer3": 40
        })

        self.brand_tiers = formula.get('brand_tiers', {
            "S": 1.5,
            "A": 1.2,
            "B": 1.0,
            "none": 0.7
        })

        self.risk_factors = formula.get('risk_factors', {
            "low": 1.0,
            "medium": 1.3,
            "high": 1.8
        })

    def filter(self, topic: str, context: Optional[str] = None) -> FilterResultV8:
        """
        è¿‡æ»¤é€‰é¢˜

        Args:
            topic: é€‰é¢˜æè¿°
            context: é¢å¤–ä¸Šä¸‹æ–‡

        Returns:
            FilterResultV8: è¿‡æ»¤ç»“æœ
        """
        full_text = f"{topic} {context or ''}".lower()
        insights = []
        score_breakdown = {}

        # Step 1: åˆ¤æ–­Layerå±‚çº§
        layer, tool_matched, tool_info = self._determine_layer(full_text)
        score_breakdown['layer_base'] = self.layer_scores.get(layer, 40)

        # Step 2: åˆ¤æ–­é€‰é¢˜ç±»å‹ï¼ˆå¯å¤šé€‰ï¼‰
        matched_types = self._match_topic_types(full_text)
        type_weight = 1.0
        for t in matched_types:
            type_weight *= self.topic_types[t].weight
        # é™åˆ¶æœ€å¤§æƒé‡
        type_weight = min(type_weight, 3.0)
        score_breakdown['type_weight'] = type_weight

        # Step 3: åˆ¤æ–­æ—¶æ•ˆæ€§
        timeliness, timeliness_boost = self._check_timeliness(full_text)
        score_breakdown['timeliness_boost'] = timeliness_boost

        # Step 4: åˆ¤æ–­å“ç‰ŒåŠ æˆ
        brand_tier = tool_info.get('tier', 'none') if tool_info else 'none'
        brand_boost = self.brand_tiers.get(brand_tier, 0.7)
        score_breakdown['brand_boost'] = brand_boost

        # Step 5: åˆ¤æ–­é£é™©ç³»æ•°
        risk_level = self._assess_risk(layer, tool_matched)
        risk_factor = self.risk_factors.get(risk_level, 1.0)
        score_breakdown['risk_factor'] = risk_factor

        # Step 6: è®¡ç®—ä¼˜å…ˆçº§åˆ†æ•°
        priority_score = (
            score_breakdown['layer_base'] *
            score_breakdown['timeliness_boost'] *
            score_breakdown['type_weight'] *
            score_breakdown['brand_boost']
        ) / score_breakdown['risk_factor']
        priority_score = round(priority_score, 1)

        # Step 7: ç”Ÿæˆåˆ†æ
        insights = self._generate_insights(
            layer, tool_matched, tool_info, matched_types,
            timeliness, risk_level, priority_score
        )

        # Step 8: ç”Ÿæˆç­–ç•¥å»ºè®®
        strategy, deadline = self._generate_strategy(
            layer, timeliness, priority_score, matched_types
        )

        # é¢„ä¼°é˜…è¯»é‡
        avg_reads = self._estimate_reads(layer, tool_info, priority_score)

        return FilterResultV8(
            layer=layer,
            worth_writing=priority_score >= 40,
            priority_score=priority_score,
            tool_matched=tool_matched,
            tool_tier=brand_tier if brand_tier != 'none' else None,
            avg_reads_estimate=avg_reads,
            topic_types=matched_types,
            timeliness=timeliness,
            risk_level=risk_level,
            strategy=strategy,
            deadline_hint=deadline,
            insights=insights,
            score_breakdown=score_breakdown
        )

    def _determine_layer(self, text: str) -> tuple:
        """åˆ¤æ–­Layerå±‚çº§"""
        # æ£€æŸ¥Layer1ï¼šæ ¸å¿ƒå·¥å…·å®˜æ–¹
        for tool_name, info in self.layer1_tools.items():
            for kw in info['keywords']:
                if kw in text:
                    return "layer1", tool_name, info

        # æ£€æŸ¥Layer2ï¼šæ ¸å¿ƒå·¥å…·ç”Ÿæ€
        for kw in self.ecosystem_keywords:
            if kw in text:
                # æ‰¾åˆ°å…³è”çš„æ ¸å¿ƒå·¥å…·
                for tool_name, info in self.layer1_tools.items():
                    for tool_kw in info['keywords']:
                        if tool_kw in text:
                            return "layer2", tool_name, info
                # æœ‰ç”Ÿæ€å…³é”®è¯ä½†æœªåŒ¹é…å…·ä½“å·¥å…·
                return "layer2", None, None

        # æ£€æŸ¥Layer3ï¼šæ³›AIè¯é¢˜
        ai_keywords = ["ai", "äººå·¥æ™ºèƒ½", "å¤§æ¨¡å‹", "llm", "agent", "æ™ºèƒ½ä½“",
                       "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "ç”Ÿæˆå¼", "aigc"]
        for kw in ai_keywords:
            if kw in text:
                return "layer3", None, None

        # ä¸ç›¸å…³
        return "rejected", None, None

    def _match_topic_types(self, text: str) -> List[str]:
        """åŒ¹é…é€‰é¢˜ç±»å‹ï¼ˆå¯å¤šé€‰ï¼‰"""
        matched = []
        for type_name, type_info in self.topic_types.items():
            for kw in type_info.keywords:
                if kw in text:
                    matched.append(type_name)
                    break
        return matched if matched else ["é€šç”¨å‹"]

    def _check_timeliness(self, text: str) -> tuple:
        """æ£€æŸ¥æ—¶æ•ˆæ€§"""
        # ç´§æ€¥çƒ­ç‚¹
        for kw in self.immediate_keywords:
            if kw in text:
                return "ç´§æ€¥çƒ­ç‚¹", self.immediate_boost

        # è¿‘æœŸæ›´æ–°
        for kw in self.recent_keywords:
            if kw in text:
                return "è¿‘æœŸæ›´æ–°", self.recent_boost

        # ç‰ˆæœ¬å·æ£€æµ‹
        if re.search(r'[vV]\d+(\.\d+)?|\b\d+\.\d+\b', text):
            return "è¿‘æœŸæ›´æ–°", self.recent_boost

        # å¸¸é’å†…å®¹
        return "å¸¸é’å†…å®¹", 1.0

    def _assess_risk(self, layer: str, tool_matched: Optional[str]) -> str:
        """è¯„ä¼°é£é™©ç­‰çº§"""
        if layer == "layer1" and tool_matched:
            return "low"
        elif layer == "layer2":
            return "medium" if tool_matched else "high"
        elif layer == "layer3":
            return "high"
        return "high"

    def _estimate_reads(self, layer: str, tool_info: Optional[dict],
                        priority_score: float) -> int:
        """é¢„ä¼°é˜…è¯»é‡"""
        base_reads = {
            "layer1": 2200,
            "layer2": 1450,
            "layer3": 908,
            "rejected": 500
        }
        base = base_reads.get(layer, 500)

        if tool_info and tool_info.get('avg_reads'):
            base = tool_info['avg_reads']

        # æ ¹æ®ä¼˜å…ˆçº§åˆ†æ•°è°ƒæ•´
        if priority_score > 200:
            return int(base * 1.3)
        elif priority_score > 100:
            return int(base * 1.1)
        return base

    def _generate_insights(self, layer, tool, tool_info, types,
                          timeliness, risk, score) -> List[str]:
        """ç”Ÿæˆåˆ†ææ´å¯Ÿ"""
        insights = []

        # Layerä¿¡æ¯
        layer_names = {
            "layer1": "æ ¸å¿ƒå·¥å…·å®˜æ–¹",
            "layer2": "æ ¸å¿ƒå·¥å…·ç”Ÿæ€",
            "layer3": "æ³›AIè¯é¢˜",
            "rejected": "ä¸ç›¸å…³"
        }
        insights.append(f"ğŸ·ï¸ Layer: {layer.upper()} ({layer_names.get(layer, 'æœªçŸ¥')})")

        # å·¥å…·ä¿¡æ¯
        if tool:
            tier = tool_info.get('tier', 'B') if tool_info else 'B'
            insights.append(f"ğŸ”§ å…³è”å·¥å…·: {tool} ({tier}çº§)")
            if tool_info and tool_info.get('avg_reads'):
                insights.append(f"ğŸ“Š å†å²å¹³å‡é˜…è¯»: {tool_info['avg_reads']}")

        # ç±»å‹ä¿¡æ¯
        if types and types != ["é€šç”¨å‹"]:
            type_icons = {
                "çƒ­ç‚¹å‹": "ğŸ”¥", "å·¥å…·å‹": "ğŸ› ï¸", "æ•™ç¨‹å‹": "ğŸ“š",
                "ç¾Šæ¯›å‹": "ğŸ’¸", "ç—›ç‚¹å‹": "ğŸ”§", "æµ‹è¯„å‹": "ğŸ“Š"
            }
            type_str = " + ".join([f"{type_icons.get(t, 'ğŸ“Œ')}{t}" for t in types])
            insights.append(f"ğŸ“‚ ç±»å‹: {type_str}")

        # æ—¶æ•ˆæ€§
        time_icons = {"ç´§æ€¥çƒ­ç‚¹": "ğŸ”´", "è¿‘æœŸæ›´æ–°": "ğŸŸ¡", "å¸¸é’å†…å®¹": "ğŸŸ¢"}
        insights.append(f"â° æ—¶æ•ˆ: {time_icons.get(timeliness, 'âšª')}{timeliness}")

        # é£é™©
        risk_icons = {"low": "âœ…ä½é£é™©", "medium": "âš ï¸ä¸­é£é™©", "high": "ğŸš¨é«˜é£é™©"}
        insights.append(f"âš¡ é£é™©: {risk_icons.get(risk, 'æœªçŸ¥')}")

        # ä¼˜å…ˆçº§è¯„åˆ¤
        if score >= 200:
            insights.append(f"ğŸ¯ ä¼˜å…ˆçº§: {score}åˆ† â†’ å¼ºçƒˆæ¨èï¼")
        elif score >= 100:
            insights.append(f"ğŸ¯ ä¼˜å…ˆçº§: {score}åˆ† â†’ æ¨è")
        elif score >= 40:
            insights.append(f"ğŸ¯ ä¼˜å…ˆçº§: {score}åˆ† â†’ å¯å†™ï¼ˆéœ€è¦è§’åº¦ï¼‰")
        else:
            insights.append(f"ğŸ¯ ä¼˜å…ˆçº§: {score}åˆ† â†’ ä¸æ¨è")

        return insights

    def _generate_strategy(self, layer, timeliness, score, types) -> tuple:
        """ç”Ÿæˆç­–ç•¥å»ºè®®"""
        if score >= 200:
            if timeliness == "ç´§æ€¥çƒ­ç‚¹":
                return "ğŸ”¥ æŠ¢é¦–å‘ï¼ç´§æ€¥è¿½çƒ­ç‚¹ï¼Œå¿«é€Ÿäº§å‡º", "24å°æ—¶å†…"
            else:
                return "âœ… é‡ç‚¹æ¨èï¼é«˜ä¼˜å…ˆçº§é€‰é¢˜", "48å°æ—¶å†…"

        elif score >= 100:
            if "æ•™ç¨‹å‹" in types:
                return "ğŸ“š åšæ·±åº¦æ•™ç¨‹ï¼Œæ‰“ç£¨è´¨é‡", "å¯æ‰“ç£¨"
            elif timeliness == "ç´§æ€¥çƒ­ç‚¹":
                return "âš¡ è¿½çƒ­ç‚¹ï¼Œå¿«é€Ÿäº§å‡º", "24å°æ—¶å†…"
            else:
                return "ğŸ‘ å€¼å¾—å†™ï¼Œæ‰¾å¥½è§’åº¦", "72å°æ—¶å†…"

        elif score >= 40:
            if layer == "layer3":
                return "ğŸ¤” è°¨æ…å†™ï¼Œéœ€è¦ç‹¬ç‰¹è§’åº¦æ‰èƒ½ç ´åœˆ", "å¯æ‰“ç£¨"
            else:
                return "ğŸ“ å¯ä»¥å†™ï¼Œä½†ä¼˜å…ˆçº§ä¸é«˜", "å¯æ‰“ç£¨"

        else:
            return "âŒ ä¸å»ºè®®å†™ï¼Œä¸æ ¸å¿ƒå·¥å…·æ— å…³ï¼Œé£é™©è¿‡é«˜", "ä¸å»ºè®®"

    def generate_report(self, result: FilterResultV8, topic: str) -> str:
        """ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"""
        lines = [
            "â•”" + "â•" * 58 + "â•—",
            "â•‘" + "ğŸ¯ é€‰é¢˜è¿‡æ»¤å™¨ V8.0 - ä¸‰å±‚æ¶æ„ç‰ˆ".center(50) + "â•‘",
            "â•š" + "â•" * 58 + "â•",
            "",
            f"ğŸ“ é€‰é¢˜ï¼š{topic}",
            "",
            "â”€" * 60,
        ]

        # æ ¸å¿ƒåˆ¤æ–­
        if result.worth_writing:
            lines.append(f"âœ… åˆ¤æ–­ï¼šå€¼å¾—å†™ï¼ˆ{result.priority_score}åˆ†ï¼‰")
        else:
            lines.append(f"âŒ åˆ¤æ–­ï¼šä¸å»ºè®®ï¼ˆ{result.priority_score}åˆ†ï¼‰")

        lines.append("")

        # åˆ†ææ˜ç»†
        lines.append("ğŸ“Š åˆ†ææ˜ç»†ï¼š")
        for insight in result.insights:
            lines.append(f"  {insight}")

        lines.extend([
            "",
            "â”€" * 60,
            f"ğŸ“‹ ç­–ç•¥ï¼š{result.strategy}",
            f"â° æ—¶é—´ï¼š{result.deadline_hint}",
            f"ğŸ“ˆ é¢„ä¼°é˜…è¯»ï¼š{result.avg_reads_estimate}",
            "",
            "â”€" * 60,
        ])

        # åˆ†æ•°æ‹†è§£
        lines.append("ğŸ”¢ åˆ†æ•°æ‹†è§£ï¼š")
        bd = result.score_breakdown
        lines.append(f"  LayeråŸºç¡€åˆ†: {bd.get('layer_base', 0)}")
        lines.append(f"  Ã— æ—¶æ•ˆæ€§åŠ æˆ: {bd.get('timeliness_boost', 1.0)}")
        lines.append(f"  Ã— ç±»å‹æƒé‡: {bd.get('type_weight', 1.0):.2f}")
        lines.append(f"  Ã— å“ç‰ŒåŠ æˆ: {bd.get('brand_boost', 1.0)}")
        lines.append(f"  Ã· é£é™©ç³»æ•°: {bd.get('risk_factor', 1.0)}")
        lines.append(f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        lines.append(f"  = æœ€ç»ˆåˆ†: {result.priority_score}")

        lines.extend([
            "",
            "â•" * 60,
            "ğŸ“Š V8æ•°æ®åŸºå‡†ï¼ˆ82ç¯‡éªŒè¯ï¼‰ï¼š",
            "â•" * 60,
            "  Layer1ï¼ˆæ ¸å¿ƒå·¥å…·å®˜æ–¹ï¼‰ï¼šå¹³å‡é˜…è¯» 2200ï¼Œçˆ†æ¬¾ç‡ 71%",
            "  Layer2ï¼ˆæ ¸å¿ƒå·¥å…·ç”Ÿæ€ï¼‰ï¼šå¹³å‡é˜…è¯» 1450ï¼Œçˆ†æ¬¾ç‡ 24%",
            "  Layer3ï¼ˆæ³›AIè¯é¢˜ï¼‰ï¼šå¹³å‡é˜…è¯» 908ï¼Œçˆ†æ¬¾ç‡ 5%",
            "",
            "  ä¼˜å…ˆçº§é˜ˆå€¼ï¼š>200å¼ºæ¨ | >100æ¨è | >40å¯å†™ | <40ä¸æ¨è",
            "",
        ])

        return "\n".join(lines)


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

    if len(sys.argv) < 2:
        print("ç”¨æ³•: python topic_filter.py <é€‰é¢˜æè¿°> [é¢å¤–ä¸Šä¸‹æ–‡]")
        print("")
        print("ç¤ºä¾‹:")
        print("  python topic_filter.py 'Claude Code 2.1å‘å¸ƒäº†'")
        print("  python topic_filter.py 'Cursoræœ€æ–°MCPæ’ä»¶æ•™ç¨‹'")
        print("  python topic_filter.py 'AIä¼šå–ä»£ç¨‹åºå‘˜å—'")
        print("  python topic_filter.py 'browsertools-mcpç¥å™¨æ¨è'")
        sys.exit(1)

    topic = sys.argv[1]
    context = sys.argv[2] if len(sys.argv) > 2 else None

    filter_tool = TopicFilterV8()
    result = filter_tool.filter(topic, context)
    print(filter_tool.generate_report(result, topic))


if __name__ == "__main__":
    main()
