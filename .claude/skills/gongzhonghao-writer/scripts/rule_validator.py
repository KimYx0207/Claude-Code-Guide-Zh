#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çˆ†æ¬¾è§„åˆ™éªŒè¯å™¨ V1.0 - æ•°æ®é©±åŠ¨è§„åˆ™è¿­ä»£

æ ¸å¿ƒæ€è·¯ï¼š
- ä¸åšç»Ÿè®¡æ¨æ–­ï¼ˆæ ·æœ¬ä¸å¤Ÿï¼‰
- åšè§„åˆ™æœ‰æ•ˆæ€§è¿½è¸ªï¼ˆæ¯æ¡è§„åˆ™å…³è”çš„æ–‡ç« è¡¨ç°ï¼‰
- è¾“å‡ºï¼šå“ªäº›è§„åˆ™æœ‰æ•ˆï¼Œå“ªäº›è§„åˆ™éœ€è¦è°ƒæ•´

ä½œè€…ï¼šè€é‡‘
æ—¥æœŸï¼š2025-12-09
"""

import json
import re
import sys
import io
from pathlib import Path
from typing import Dict, List, Any, Tuple
from collections import defaultdict
from datetime import datetime

# Windows UTF-8å…¼å®¹
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')


class RuleValidator:
    """è§„åˆ™éªŒè¯å™¨ - æ£€éªŒç°æœ‰è§„åˆ™çš„å®é™…æœ‰æ•ˆæ€§"""

    def __init__(self, data_file: str):
        self.data_file = Path(data_file)
        self.articles: List[Dict] = []
        self.rules: Dict[str, Dict] = {}
        self.rule_hits: Dict[str, List[Dict]] = defaultdict(list)

        # å®šä¹‰è§„åˆ™æ£€æµ‹å™¨ï¼ˆåŸºäºbaokuan-rules.mdä¸­çš„è§„åˆ™ï¼‰
        self._init_rules()

    def _init_rules(self):
        """åˆå§‹åŒ–è§„åˆ™å®šä¹‰"""
        self.rules = {
            # === æ ‡é¢˜è§„åˆ™ ===
            "brand_word": {
                "name": "å“ç‰Œè¯",
                "description": "æ ‡é¢˜å«Claude/Cursor/Gemini/ChatGPTç­‰å“ç‰Œè¯",
                "weight": 30,  # baokuan-rulesä¸­å®šä¹‰çš„æƒé‡
                "detector": self._detect_brand_word
            },
            "number_shock": {
                "name": "æ•°å­—å†²å‡»",
                "description": "æ ‡é¢˜å«å…·ä½“æ•°å­—ï¼ˆå€æ•°ã€ç™¾åˆ†æ¯”ã€é‡‘é¢ç­‰ï¼‰",
                "weight": 10,
                "detector": self._detect_number_shock
            },
            "efficiency_promise": {
                "name": "æ•ˆç‡æ‰¿è¯º",
                "description": "æ ‡é¢˜å«ä¸€é”®/ç§’/åˆ†é’Ÿç­‰æ•ˆç‡è¯",
                "weight": 10,
                "detector": self._detect_efficiency_promise
            },
            "tutorial_word": {
                "name": "æ•™ç¨‹è¯",
                "description": "æ ‡é¢˜å«æ‰‹æŠŠæ‰‹/æ•™ç¨‹/æ•™ä½ ç­‰è¯",
                "weight": 15,
                "detector": self._detect_tutorial_word
            },
            "tool_word": {
                "name": "å·¥å…·è¯",
                "description": "æ ‡é¢˜å«ç¥å™¨/å·¥å…·/åˆ©å™¨ç­‰è¯",
                "weight": 10,
                "detector": self._detect_tool_word
            },
            "emotion_word": {
                "name": "æƒ…ç»ªè¯",
                "description": "æ ‡é¢˜å«æƒŠäº†/éº»äº†/å“åˆ°/æ…Œäº†ç­‰æƒ…ç»ªè¯",
                "weight": 10,
                "detector": self._detect_emotion_word
            },
            "question_mark": {
                "name": "é—®å·",
                "description": "æ ‡é¢˜å«é—®å·ï¼ˆåˆ¶é€ æ‚¬å¿µï¼‰",
                "weight": 5,
                "detector": self._detect_question_mark
            },
            "fomo_word": {
                "name": "FOMOè¯",
                "description": "æ ‡é¢˜å«99%/ä¸çŸ¥é“/é”™è¿‡ç­‰FOMOè¯",
                "weight": 15,
                "detector": self._detect_fomo_word
            },
            "time_word": {
                "name": "æ—¶æ•ˆè¯",
                "description": "æ ‡é¢˜å«æ˜¨æ™š/ä»Šå¤©/åˆšåˆšç­‰æ—¶æ•ˆè¯",
                "weight": 20,
                "detector": self._detect_time_word
            },
            "personal_word": {
                "name": "ä¸ªäººè§†è§’",
                "description": "æ ‡é¢˜å«è€é‡‘/æˆ‘/æ‰çŸ¥é“ç­‰ä¸ªäººè§†è§’è¯",
                "weight": 10,
                "detector": self._detect_personal_word
            },

            # === æ ‡é¢˜é•¿åº¦è§„åˆ™ ===
            "title_length_optimal": {
                "name": "æ ‡é¢˜é•¿åº¦æœ€ä½³",
                "description": "æ ‡é¢˜é•¿åº¦15-25å­—",
                "weight": 5,
                "detector": self._detect_title_length_optimal
            },

            # === æ ‡é¢˜å…¬å¼è§„åˆ™ï¼ˆæ£€æµ‹æ˜¯å¦ç¬¦åˆ12å¤§å…¬å¼ä¹‹ä¸€ï¼‰===
            "formula_pain_solve": {
                "name": "ç—›ç‚¹è§£å†³å…¬å¼",
                "description": "å“ç‰Œè¯+é—®é¢˜+æ‰‹æŠŠæ‰‹æ•™ä½ ",
                "weight": 25,
                "detector": self._detect_formula_pain_solve
            },
            "formula_tool_recommend": {
                "name": "å·¥å…·æ¨èå…¬å¼",
                "description": "ç”¨äº†Xæ—¶é—´æ‰çŸ¥é“+ç¥å™¨",
                "weight": 20,
                "detector": self._detect_formula_tool_recommend
            },
            "formula_version_update": {
                "name": "ç‰ˆæœ¬æ›´æ–°å…¬å¼",
                "description": "å“ç‰Œè¯+ç‰ˆæœ¬å·+è§£è¯»/å®æµ‹",
                "weight": 15,
                "detector": self._detect_formula_version_update
            },
        }

    # === è§„åˆ™æ£€æµ‹å‡½æ•° ===

    def _detect_brand_word(self, title: str, content: str = "") -> bool:
        """æ£€æµ‹å“ç‰Œè¯"""
        brands = [
            'claude', 'cursor', 'gemini', 'chatgpt', 'gpt', 'openai',
            'anthropic', 'copilot', 'midjourney', 'suno', 'kimi',
            'jetbrains', 'vscode', 'notion', 'figma', 'lovart',
            'mcp', 'skills', 'hooks'
        ]
        title_lower = title.lower()
        return any(brand in title_lower for brand in brands)

    def _detect_number_shock(self, title: str, content: str = "") -> bool:
        """æ£€æµ‹æ•°å­—å†²å‡»"""
        # åŒ¹é…ï¼šæ•°å­—+å€ã€æ•°å­—+%ã€æ•°å­—+ä¸‡ã€æ•°å­—+å—/å…ƒã€æ—¶é—´å¯¹æ¯”
        patterns = [
            r'\d+å€',
            r'\d+%',
            r'\d+ä¸‡',
            r'\d+å—',
            r'\d+å…ƒ',
            r'\d+\$',
            r'\d+å°æ—¶',
            r'\d+åˆ†é’Ÿ',
            r'\d+å¤©',
            r'\d+ä¸ª',
            r'\d+æ¬¾',
            r'\d+ç¯‡',
            r'\d+æ˜Ÿ',  # GitHubæ˜Ÿæ•°
            r'ä»\d+åˆ°\d+',  # å¯¹æ¯”
        ]
        return any(re.search(p, title) for p in patterns)

    def _detect_efficiency_promise(self, title: str, content: str = "") -> bool:
        """æ£€æµ‹æ•ˆç‡æ‰¿è¯ºè¯"""
        words = ['ä¸€é”®', 'ç§’', 'åˆ†é’Ÿæå®š', 'å¿«é€Ÿ', 'è‡ªåŠ¨', 'ç«‹å³', 'é©¬ä¸Š']
        return any(w in title for w in words)

    def _detect_tutorial_word(self, title: str, content: str = "") -> bool:
        """æ£€æµ‹æ•™ç¨‹è¯"""
        words = ['æ‰‹æŠŠæ‰‹', 'æ•™ç¨‹', 'æ•™ä½ ', 'æŒ‡å—', 'æ”»ç•¥', 'è¯¦è§£', 'æ€ä¹ˆ']
        return any(w in title for w in words)

    def _detect_tool_word(self, title: str, content: str = "") -> bool:
        """æ£€æµ‹å·¥å…·è¯"""
        words = ['ç¥å™¨', 'å·¥å…·', 'åˆ©å™¨', 'æ’ä»¶', 'æ‰©å±•', 'æŠ€èƒ½', 'Skill']
        return any(w in title for w in words)

    def _detect_emotion_word(self, title: str, content: str = "") -> bool:
        """æ£€æµ‹æƒ…ç»ªè¯"""
        words = ['æƒŠäº†', 'éº»äº†', 'å“åˆ°', 'æ…Œäº†', 'ç»äº†', 'ç‰›é€¼', 'å¤ªç§€',
                 'çœŸé¦™', 'éœ‡æƒŠ', 'ç–¯äº†', 'å‚»äº†', 'æ‡µäº†', 'æœäº†']
        return any(w in title for w in words)

    def _detect_question_mark(self, title: str, content: str = "") -> bool:
        """æ£€æµ‹é—®å·"""
        return 'ï¼Ÿ' in title or '?' in title

    def _detect_fomo_word(self, title: str, content: str = "") -> bool:
        """æ£€æµ‹FOMOè¯ï¼ˆé”™è¿‡ç„¦è™‘ï¼‰"""
        words = ['99%', 'ä¸çŸ¥é“', 'é”™è¿‡', 'å¿…çœ‹', 'å¿…é¡»', 'åƒä¸‡åˆ«', 'å±…ç„¶']
        return any(w in title for w in words)

    def _detect_time_word(self, title: str, content: str = "") -> bool:
        """æ£€æµ‹æ—¶æ•ˆè¯"""
        words = ['æ˜¨æ™š', 'ä»Šå¤©', 'åˆšåˆš', 'æœ€æ–°', 'ä»Šæ—©', 'å‡Œæ™¨', 'ä¸Šçº¿', 'å‘å¸ƒ']
        return any(w in title for w in words)

    def _detect_personal_word(self, title: str, content: str = "") -> bool:
        """æ£€æµ‹ä¸ªäººè§†è§’è¯"""
        words = ['è€é‡‘', 'æˆ‘', 'æ‰çŸ¥é“', 'æ‰å‘ç°', 'ç»ˆäº']
        return any(w in title for w in words)

    def _detect_title_length_optimal(self, title: str, content: str = "") -> bool:
        """æ£€æµ‹æ ‡é¢˜é•¿åº¦æ˜¯å¦åœ¨15-25å­—"""
        length = len(title)
        return 15 <= length <= 25

    def _detect_formula_pain_solve(self, title: str, content: str = "") -> bool:
        """æ£€æµ‹ç—›ç‚¹è§£å†³å…¬å¼ï¼šå“ç‰Œè¯+é—®é¢˜+æ‰‹æŠŠæ‰‹"""
        has_brand = self._detect_brand_word(title)
        has_question = '?' in title or 'ï¼Ÿ' in title
        has_tutorial = any(w in title for w in ['æ‰‹æŠŠæ‰‹', 'æ•™ä½ ', 'æ€ä¹ˆ'])
        return has_brand and (has_question or has_tutorial)

    def _detect_formula_tool_recommend(self, title: str, content: str = "") -> bool:
        """æ£€æµ‹å·¥å…·æ¨èå…¬å¼ï¼šæ—¶é—´+æ‰çŸ¥é“+ç¥å™¨"""
        has_time = any(w in title for w in ['ç”¨äº†', 'åŠå¹´', 'ä¸€å¹´', 'ä¸ªæœˆ'])
        has_discover = any(w in title for w in ['æ‰çŸ¥é“', 'æ‰å‘ç°', 'åŸæ¥'])
        has_tool = any(w in title for w in ['ç¥å™¨', 'å·¥å…·', 'è¿™ä¸ª'])
        return has_time and has_discover

    def _detect_formula_version_update(self, title: str, content: str = "") -> bool:
        """æ£€æµ‹ç‰ˆæœ¬æ›´æ–°å…¬å¼ï¼šå“ç‰Œè¯+ç‰ˆæœ¬å·"""
        has_brand = self._detect_brand_word(title)
        has_version = bool(re.search(r'[vV]?\d+\.?\d*', title))
        return has_brand and has_version

    # === æ ¸å¿ƒåˆ†ææ–¹æ³• ===

    def load_data(self) -> bool:
        """åŠ è½½æ–‡ç« æ•°æ®"""
        if not self.data_file.exists():
            print(f"âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ï¼š{self.data_file}")
            return False

        try:
            with open(self.data_file, 'r', encoding='utf-8') as f:
                self.articles = json.load(f)
            print(f"âœ… åŠ è½½ {len(self.articles)} ç¯‡æ–‡ç« ")
            return True
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥ï¼š{e}")
            return False

    def analyze_rules(self) -> Dict[str, Any]:
        """åˆ†ææ¯æ¡è§„åˆ™çš„æœ‰æ•ˆæ€§"""
        results = {}

        # è®¡ç®—å…¨å±€å¹³å‡é˜…è¯»é‡
        all_reads = [a.get('read_count', 0) for a in self.articles]
        global_avg = sum(all_reads) / len(all_reads) if all_reads else 0

        print(f"\nğŸ“Š å…¨å±€å¹³å‡é˜…è¯»ï¼š{global_avg:.0f}")
        print("=" * 60)

        for rule_id, rule in self.rules.items():
            # æ£€æµ‹æ¯ç¯‡æ–‡ç« æ˜¯å¦å‘½ä¸­è¯¥è§„åˆ™
            hit_articles = []
            miss_articles = []

            for article in self.articles:
                title = article.get('title', '')
                content = article.get('content', '')
                read_count = article.get('read_count', 0)

                if rule['detector'](title, content):
                    hit_articles.append({
                        'title': title,
                        'read': read_count,
                        'like': article.get('like_count', 0)
                    })
                else:
                    miss_articles.append({
                        'title': title,
                        'read': read_count
                    })

            # è®¡ç®—æœ‰æ•ˆæ€§
            hit_count = len(hit_articles)
            miss_count = len(miss_articles)
            hit_rate = hit_count / len(self.articles) * 100 if self.articles else 0

            avg_read_hit = sum(a['read'] for a in hit_articles) / hit_count if hit_count else 0
            avg_read_miss = sum(a['read'] for a in miss_articles) / miss_count if miss_count else 0

            # æœ‰æ•ˆæ€§ = å‘½ä¸­æ—¶å¹³å‡é˜…è¯» / æœªå‘½ä¸­æ—¶å¹³å‡é˜…è¯»
            effectiveness = avg_read_hit / avg_read_miss if avg_read_miss > 0 else 0

            # ç›¸å¯¹å…¨å±€çš„æå‡
            lift_vs_global = (avg_read_hit - global_avg) / global_avg * 100 if global_avg > 0 else 0

            results[rule_id] = {
                'name': rule['name'],
                'description': rule['description'],
                'original_weight': rule['weight'],
                'hit_count': hit_count,
                'miss_count': miss_count,
                'hit_rate': round(hit_rate, 1),
                'avg_read_when_hit': round(avg_read_hit, 0),
                'avg_read_when_miss': round(avg_read_miss, 0),
                'effectiveness': round(effectiveness, 2),
                'lift_vs_global': round(lift_vs_global, 1),
                'top_3_hits': sorted(hit_articles, key=lambda x: -x['read'])[:3],
                'recommendation': self._get_recommendation(effectiveness, hit_rate)
            }

        return results

    def _get_recommendation(self, effectiveness: float, hit_rate: float) -> str:
        """æ ¹æ®æœ‰æ•ˆæ€§ç»™å‡ºå»ºè®®"""
        if effectiveness >= 1.5 and hit_rate >= 20:
            return "ğŸ”¥ å¼ºæ•ˆè§„åˆ™ï¼Œç»§ç»­å¼ºåŒ–"
        elif effectiveness >= 1.2:
            return "âœ… æœ‰æ•ˆè§„åˆ™ï¼Œä¿æŒä½¿ç”¨"
        elif effectiveness >= 0.8:
            return "âš ï¸ æ•ˆæœä¸€èˆ¬ï¼Œéœ€è¦ä¼˜åŒ–"
        else:
            return "âŒ æ— æ•ˆè§„åˆ™ï¼Œè€ƒè™‘åˆ é™¤"

    def print_report(self, results: Dict[str, Any]):
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“Š çˆ†æ¬¾è§„åˆ™æœ‰æ•ˆæ€§åˆ†ææŠ¥å‘Š")
        print("=" * 60)

        # æŒ‰æœ‰æ•ˆæ€§æ’åº
        sorted_rules = sorted(results.items(), key=lambda x: -x[1]['effectiveness'])

        print("\n### è§„åˆ™æœ‰æ•ˆæ€§æ’è¡Œæ¦œ\n")
        print("| æ’å | è§„åˆ™ | å‘½ä¸­ç‡ | å‘½ä¸­å‡è¯» | æœªå‘½ä¸­å‡è¯» | æœ‰æ•ˆæ€§ | å»ºè®® |")
        print("|------|------|--------|----------|------------|--------|------|")

        for i, (rule_id, data) in enumerate(sorted_rules, 1):
            print(f"| {i} | {data['name']} | {data['hit_rate']}% | {data['avg_read_when_hit']:.0f} | {data['avg_read_when_miss']:.0f} | {data['effectiveness']:.2f}x | {data['recommendation']} |")

        # è¯¦ç»†åˆ†æ
        print("\n\n### è¯¦ç»†åˆ†æ\n")

        for rule_id, data in sorted_rules:
            print(f"\n#### {data['name']}ï¼ˆ{rule_id}ï¼‰")
            print(f"- **æè¿°**ï¼š{data['description']}")
            print(f"- **åŸå§‹æƒé‡**ï¼š{data['original_weight']}åˆ†")
            print(f"- **å‘½ä¸­/æœªå‘½ä¸­**ï¼š{data['hit_count']}ç¯‡ / {data['miss_count']}ç¯‡")
            print(f"- **å‘½ä¸­æ—¶å‡è¯»**ï¼š{data['avg_read_when_hit']:.0f}")
            print(f"- **æœªå‘½ä¸­å‡è¯»**ï¼š{data['avg_read_when_miss']:.0f}")
            print(f"- **æœ‰æ•ˆæ€§**ï¼š{data['effectiveness']:.2f}x")
            print(f"- **ç›¸å¯¹å…¨å±€æå‡**ï¼š{data['lift_vs_global']:+.1f}%")
            print(f"- **å»ºè®®**ï¼š{data['recommendation']}")

            if data['top_3_hits']:
                print(f"- **å‘½ä¸­TOP 3**ï¼š")
                for j, hit in enumerate(data['top_3_hits'], 1):
                    print(f"  {j}. {hit['title'][:30]}... ({hit['read']}é˜…è¯»)")

        # æ€»ç»“å»ºè®®
        print("\n\n### è§„åˆ™ä¼˜åŒ–å»ºè®®\n")

        strong_rules = [r for r in sorted_rules if r[1]['effectiveness'] >= 1.5]
        weak_rules = [r for r in sorted_rules if r[1]['effectiveness'] < 0.8]

        if strong_rules:
            print("**å¼ºæ•ˆè§„åˆ™ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰**ï¼š")
            for rule_id, data in strong_rules:
                print(f"- {data['name']}ï¼šæœ‰æ•ˆæ€§{data['effectiveness']:.2f}x")

        if weak_rules:
            print("\n**ä½æ•ˆè§„åˆ™ï¼ˆè€ƒè™‘è°ƒæ•´ï¼‰**ï¼š")
            for rule_id, data in weak_rules:
                print(f"- {data['name']}ï¼šæœ‰æ•ˆæ€§{data['effectiveness']:.2f}x")

    def save_report(self, results: Dict[str, Any], output_file: str = None):
        """ä¿å­˜åˆ†ææŠ¥å‘Šä¸ºJSON"""
        if output_file is None:
            output_file = self.data_file.parent / "rule_validation_report.json"

        report = {
            "metadata": {
                "analysis_date": datetime.now().isoformat(),
                "total_articles": len(self.articles),
                "rules_analyzed": len(results)
            },
            "rules": results,
            "summary": {
                "strong_rules": [r for r, d in results.items() if d['effectiveness'] >= 1.5],
                "effective_rules": [r for r, d in results.items() if 1.2 <= d['effectiveness'] < 1.5],
                "weak_rules": [r for r, d in results.items() if d['effectiveness'] < 0.8]
            }
        }

        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜ï¼š{output_file}")
        except Exception as e:
            print(f"\nâŒ ä¿å­˜å¤±è´¥ï¼š{e}")


def main():
    """ä¸»å‡½æ•°"""
    # é»˜è®¤æ•°æ®æ–‡ä»¶è·¯å¾„
    if len(sys.argv) > 1:
        data_file = sys.argv[1]
    else:
        # å°è¯•æ‰¾åˆ°dataç›®å½•
        script_dir = Path(__file__).parent
        data_file = script_dir.parent.parent.parent.parent / "data" / "wechat_articles.json"

    print("=" * 60)
    print("ğŸ“Š çˆ†æ¬¾è§„åˆ™éªŒè¯å™¨ V1.0")
    print("=" * 60)
    print(f"æ•°æ®æ–‡ä»¶ï¼š{data_file}")

    validator = RuleValidator(data_file)

    if not validator.load_data():
        return

    results = validator.analyze_rules()
    validator.print_report(results)
    validator.save_report(results)

    print("\n" + "=" * 60)
    print("ğŸ’¡ ä½¿ç”¨å»ºè®®ï¼š")
    print("   1. å¼ºæ•ˆè§„åˆ™ï¼ˆ>1.5xï¼‰ï¼šå†™ä½œæ—¶ä¼˜å…ˆä½¿ç”¨")
    print("   2. æœ‰æ•ˆè§„åˆ™ï¼ˆ1.2-1.5xï¼‰ï¼šæ­£å¸¸ä½¿ç”¨")
    print("   3. ä½æ•ˆè§„åˆ™ï¼ˆ<0.8xï¼‰ï¼šè€ƒè™‘è°ƒæ•´æˆ–åˆ é™¤")
    print("   4. å®šæœŸè¿è¡Œæ­¤è„šæœ¬ï¼Œè¿½è¸ªè§„åˆ™æœ‰æ•ˆæ€§å˜åŒ–")
    print("=" * 60)


if __name__ == "__main__":
    main()
