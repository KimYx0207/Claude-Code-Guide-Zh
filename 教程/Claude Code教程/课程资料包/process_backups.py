#!/usr/bin/env python3
"""
æ•´åˆæ•™ç¨‹å¤‡ä»½æ–‡ä»¶è„šæœ¬
å»é™¤é‡å¤å†…å®¹,é‡ç»„ç« èŠ‚,ç”Ÿæˆæ¸…æ™°çš„æ•™ç¨‹æ–‡æ¡£
"""

import re
from pathlib import Path
from collections import defaultdict

def read_file(filepath):
    """è¯»å–æ–‡ä»¶å†…å®¹"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return f.read()

def write_file(filepath, content):
    """å†™å…¥æ–‡ä»¶å†…å®¹"""
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)

def extract_sections(content):
    """æå–ç« èŠ‚ç»“æ„"""
    lines = content.split('\n')
    sections = []
    current_section = {'level': 0, 'title': '', 'content': [], 'line_start': 0}

    for i, line in enumerate(lines):
        # åŒ¹é…æ ‡é¢˜
        match = re.match(r'^(#{1,6})\s+(.+)$', line)
        if match:
            if current_section['content']:
                sections.append(current_section)

            level = len(match.group(1))
            title = match.group(2).strip()
            current_section = {
                'level': level,
                'title': title,
                'content': [line],
                'line_start': i
            }
        else:
            current_section['content'].append(line)

    if current_section['content']:
        sections.append(current_section)

    return sections

def deduplicate_sections(sections):
    """å»é™¤é‡å¤ç« èŠ‚"""
    seen_titles = {}
    unique_sections = []
    duplicates_removed = []

    for section in sections:
        key = f"{section['level']}:{section['title']}"

        if key not in seen_titles:
            seen_titles[key] = section
            unique_sections.append(section)
        else:
            # ä¿ç•™å†…å®¹æ›´é•¿çš„ç‰ˆæœ¬
            existing = seen_titles[key]
            if len('\n'.join(section['content'])) > len('\n'.join(existing['content'])):
                # æ›¿æ¢ä¸ºæ›´è¯¦ç»†çš„ç‰ˆæœ¬
                idx = unique_sections.index(existing)
                unique_sections[idx] = section
                seen_titles[key] = section
                duplicates_removed.append(f"{key} (ä¿ç•™æ›´è¯¦ç»†ç‰ˆæœ¬)")
            else:
                duplicates_removed.append(key)

    return unique_sections, duplicates_removed

def organize_sections(sections, doc_type):
    """é‡ç»„ç« èŠ‚ç»“æ„"""
    organized = []

    if doc_type == 'installation':
        # ç¯å¢ƒæ­å»ºæŒ‡å—çš„ç»„ç»‡ç»“æ„
        order = [
            'Claude Codeç®€ä»‹',
            'Node.jsç¯å¢ƒå‡†å¤‡',
            'ç³»ç»Ÿè¦æ±‚æ£€æŸ¥',
            'Anthropic APIé…ç½®',
            'Claude Codeå®‰è£…',
            'éªŒè¯ä¸æµ‹è¯•',
            'å¸¸è§é—®é¢˜',
            'æ•…éšœæ’æŸ¥'
        ]
    else:  # basic_usage
        # åŸºç¡€ä½¿ç”¨æŒ‡å—çš„ç»„ç»‡ç»“æ„
        order = [
            'å‘½ä»¤é€ŸæŸ¥è¡¨',
            'åŸºç¡€å‘½ä»¤',
            'äº¤äº’æ¨¡å¼',
            'é…ç½®ç®¡ç†',
            'è¯Šæ–­å·¥å…·',
            'é«˜çº§åŠŸèƒ½',
            'æœ€ä½³å®è·µ'
        ]

    # æŒ‰ç…§é¢„å®šé¡ºåºç»„ç»‡
    for category in order:
        matching = [s for s in sections if category.lower() in s['title'].lower()]
        organized.extend(matching)

    # æ·»åŠ æœªåŒ¹é…çš„ç« èŠ‚
    organized_titles = {s['title'] for s in organized}
    remaining = [s for s in sections if s['title'] not in organized_titles]
    organized.extend(remaining)

    return organized

def clean_content(content):
    """æ¸…ç†å†…å®¹,å»é™¤å¤šä½™ç©ºè¡Œå’Œæ ¼å¼é—®é¢˜"""
    lines = content.split('\n')
    cleaned = []
    prev_empty = False

    for line in lines:
        is_empty = not line.strip()

        # æœ€å¤šè¿ç»­ä¸¤ä¸ªç©ºè¡Œ
        if is_empty and prev_empty:
            continue

        cleaned.append(line)
        prev_empty = is_empty

    return '\n'.join(cleaned)

def generate_toc(sections):
    """ç”Ÿæˆç›®å½•"""
    toc = ["## ğŸ“‹ ç›®å½•\n"]

    for section in sections:
        if section['level'] == 1:
            continue  # è·³è¿‡æ–‡æ¡£æ ‡é¢˜

        indent = "  " * (section['level'] - 2)
        title = section['title']
        # ç”Ÿæˆé”šç‚¹é“¾æ¥
        anchor = re.sub(r'[^\w\u4e00-\u9fff-]', '', title.lower().replace(' ', '-'))
        toc.append(f"{indent}- [{title}](#{anchor})")

    toc.append("\n---\n")
    return '\n'.join(toc)

def process_backup1(input_path, output_path):
    """å¤„ç†å¤‡ä»½1 - ç¯å¢ƒä¸å®‰è£…"""
    print(f"\nå¤„ç† {input_path.name}...".encode('utf-8', errors='ignore').decode('utf-8'))

    content = read_file(input_path)
    original_lines = len(content.split('\n'))

    # æå–ç« èŠ‚
    sections = extract_sections(content)
    print(f"  æå–åˆ° {len(sections)} ä¸ªç« èŠ‚".encode('utf-8', errors='ignore').decode('utf-8'))

    # å»é‡
    unique_sections, duplicates = deduplicate_sections(sections)
    print(f"  å»é™¤ {len(duplicates)} ä¸ªé‡å¤ç« èŠ‚".encode('utf-8', errors='ignore').decode('utf-8'))

    # é‡ç»„
    organized = organize_sections(unique_sections, 'installation')

    # ç”Ÿæˆæ–°æ–‡æ¡£
    header = """# Claude Codeç¯å¢ƒæ­å»ºå®Œå…¨æŒ‡å—

**ç‰ˆæœ¬**: v2.0
**æ›´æ–°**: 2025å¹´12æœˆ
**éš¾åº¦**: â­ é›¶åŸºç¡€å…¥é—¨
**é¢„è®¡å­¦æ—¶**: 4å°æ—¶

---

## ğŸ“š å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬æŒ‡å—å­¦ä¹ å,ä½ å°†èƒ½å¤Ÿ:

1. âœ… ç†è§£Claude Codeçš„æ ¸å¿ƒä»·å€¼ä¸åº”ç”¨åœºæ™¯
2. âœ… åœ¨ä»»æ„æ“ä½œç³»ç»Ÿä¸Šæ­£ç¡®å®‰è£…Node.jsè¿è¡Œç¯å¢ƒ
3. âœ… è·å–å¹¶é…ç½®Anthropic APIå¯†é’¥
4. âœ… æˆåŠŸå®‰è£…Claude Codeå¹¶é€šè¿‡éªŒè¯æµ‹è¯•
5. âœ… ç‹¬ç«‹è§£å†³90%çš„å¸¸è§å®‰è£…é—®é¢˜
6. âœ… æŒæ¡ç¯å¢ƒè¯Šæ–­ä¸æ•…éšœæ’æŸ¥æŠ€èƒ½

---

"""

    # ç”Ÿæˆç›®å½•
    toc = generate_toc(organized)

    # ç»„è£…å†…å®¹
    body = '\n'.join('\n'.join(s['content']) for s in organized)
    body = clean_content(body)

    final_content = header + toc + body
    final_lines = len(final_content.split('\n'))

    # å†™å…¥æ–‡ä»¶
    write_file(output_path, final_content)

    print(f"  âœ“ ç”Ÿæˆå®Œæˆ: {output_path.name}")
    print(f"  åŸå§‹è¡Œæ•°: {original_lines}")
    print(f"  æœ€ç»ˆè¡Œæ•°: {final_lines}")
    print(f"  å‹ç¼©ç‡: {(1 - final_lines/original_lines)*100:.1f}%")

    return duplicates

def process_backup2(input_path, output_path):
    """å¤„ç†å¤‡ä»½2 - åŸºç¡€ä½¿ç”¨"""
    print(f"\nå¤„ç† {input_path.name}...")

    content = read_file(input_path)
    original_lines = len(content.split('\n'))

    # æå–ç« èŠ‚
    sections = extract_sections(content)
    print(f"  æå–åˆ° {len(sections)} ä¸ªç« èŠ‚")

    # å»é‡
    unique_sections, duplicates = deduplicate_sections(sections)
    print(f"  å»é™¤ {len(duplicates)} ä¸ªé‡å¤ç« èŠ‚")

    # é‡ç»„
    organized = organize_sections(unique_sections, 'basic_usage')

    # ç”Ÿæˆæ–°æ–‡æ¡£
    header = """# Claude CodeåŸºç¡€ä½¿ç”¨å®Œå…¨æŒ‡å—

**ç‰ˆæœ¬**: v2.0
**æ›´æ–°**: 2025å¹´12æœˆ
**éš¾åº¦**: â­â­ åŸºç¡€è¿›é˜¶
**é¢„è®¡å­¦æ—¶**: 6å°æ—¶

---

## ğŸ“š å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬æŒ‡å—å­¦ä¹ å,ä½ å°†èƒ½å¤Ÿ:

1. âœ… æŒæ¡Claude Codeæ‰€æœ‰æ ¸å¿ƒå‘½ä»¤çš„ä½¿ç”¨æ–¹æ³•
2. âœ… ç†Ÿç»ƒä½¿ç”¨äº¤äº’æ¨¡å¼è¿›è¡Œå¼€å‘åä½œ
3. âœ… ç†è§£å¹¶é…ç½®é¡¹ç›®çº§ä¸å…¨å±€çº§é…ç½®
4. âœ… ä½¿ç”¨è¯Šæ–­å·¥å…·è§£å†³å¸¸è§é—®é¢˜
5. âœ… è¿ç”¨é«˜çº§åŠŸèƒ½æå‡å¼€å‘æ•ˆç‡
6. âœ… å»ºç«‹Claude Codeå¼€å‘æœ€ä½³å®è·µ

---

"""

    # ç”Ÿæˆç›®å½•
    toc = generate_toc(organized)

    # ç»„è£…å†…å®¹
    body = '\n'.join('\n'.join(s['content']) for s in organized)
    body = clean_content(body)

    final_content = header + toc + body
    final_lines = len(final_content.split('\n'))

    # å†™å…¥æ–‡ä»¶
    write_file(output_path, final_content)

    print(f"  âœ“ ç”Ÿæˆå®Œæˆ: {output_path.name}")
    print(f"  åŸå§‹è¡Œæ•°: {original_lines}")
    print(f"  æœ€ç»ˆè¡Œæ•°: {final_lines}")
    print(f"  å‹ç¼©ç‡: {(1 - final_lines/original_lines)*100:.1f}%")

    return duplicates

def main():
    """ä¸»å‡½æ•°"""
    base_path = Path(__file__).parent

    # è¾“å…¥æ–‡ä»¶
    backup1 = base_path / "01-ç¯å¢ƒä¸å®‰è£…" / "å¤‡ä»½1.md"
    backup2 = base_path / "02-åŸºç¡€ä½¿ç”¨" / "å¤‡ä»½2.md"

    # è¾“å‡ºæ–‡ä»¶
    output1 = base_path / "01-ç¯å¢ƒä¸å®‰è£…" / "Claude Codeç¯å¢ƒæ­å»ºå®Œå…¨æŒ‡å—.md"
    output2 = base_path / "02-åŸºç¡€ä½¿ç”¨" / "Claude CodeåŸºç¡€ä½¿ç”¨å®Œå…¨æŒ‡å—.md"

    print("=" * 60)
    print("Claude Codeæ•™ç¨‹æ•´åˆå·¥å…· v1.0")
    print("=" * 60)

    # å¤„ç†å¤‡ä»½1
    duplicates1 = process_backup1(backup1, output1)

    # å¤„ç†å¤‡ä»½2
    duplicates2 = process_backup2(backup2, output2)

    # æ€»ç»“æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("æ•´åˆå®ŒæˆæŠ¥å‘Š")
    print("=" * 60)

    print(f"\nğŸ“„ æ–‡ä»¶1: ç¯å¢ƒæ­å»ºæŒ‡å—")
    print(f"  å»é™¤é‡å¤: {len(duplicates1)} ä¸ªç« èŠ‚")
    if duplicates1[:5]:
        print(f"  ç¤ºä¾‹: {duplicates1[0]}")

    print(f"\nğŸ“„ æ–‡ä»¶2: åŸºç¡€ä½¿ç”¨æŒ‡å—")
    print(f"  å»é™¤é‡å¤: {len(duplicates2)} ä¸ªç« èŠ‚")
    if duplicates2[:5]:
        print(f"  ç¤ºä¾‹: {duplicates2[0]}")

    print("\nâœ… æ‰€æœ‰æ–‡ä»¶å·²ç”Ÿæˆ!")
    print(f"\nè¾“å‡ºä½ç½®:")
    print(f"  - {output1}")
    print(f"  - {output2}")

    print("\nğŸ“‹ ä¸‹ä¸€æ­¥:")
    print("  1. æ£€æŸ¥ç”Ÿæˆçš„æ–‡æ¡£å†…å®¹")
    print("  2. ç¡®è®¤æ— è¯¯ååˆ é™¤å¤‡ä»½æ–‡ä»¶")
    print("  3. è¿è¡Œ: del å¤‡ä»½1.md å¤‡ä»½2.md")

if __name__ == "__main__":
    main()
